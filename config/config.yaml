llm:
  default_provider: openai
  providers:
    openai:
      model: gpt-4
      temperature: 0.7
    anthropic:
      model: claude-2
      temperature: 0.7
    groq:
      model: mixtral-8x7b-32768
      temperature: 0.7

tools:
  code_analysis:
    default_language: python
    linting_rules: strict
  simulation:
    default_engine: numpy
    precision: double
  documentation:
    default_format: markdown
    auto_generate: true

security:
  api_key_env_prefix: SEA_
  encryption_enabled: true

logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
